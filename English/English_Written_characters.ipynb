{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English Written characters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmN4Kfp+FJR3SIvI4xPkC2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "989554b46ce345e988e2bf33949f7a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_925d02b3a7d94f00a919edb0e363390a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_93d1644e1c844d34a3116e1a7a060638",
              "IPY_MODEL_a8d0cf6c528045a6bf0ecc28d8934989",
              "IPY_MODEL_a8861ab6b3be4c8db3d98cf26f0108a9"
            ]
          }
        },
        "925d02b3a7d94f00a919edb0e363390a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "93d1644e1c844d34a3116e1a7a060638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e3a9069c6ca4af0aa1be6bef90e7016",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_631119b3ca804418b2624d97b8ca1b9d"
          }
        },
        "a8d0cf6c528045a6bf0ecc28d8934989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_561e9623d3c24907a9c6f7e971d144f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46830571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46830571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02c9cb6137844ba0b99b00353e4ffa00"
          }
        },
        "a8861ab6b3be4c8db3d98cf26f0108a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55ad78ac9a5b4ff3aae7521266903bde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 71.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c301ce9e4b644d2090ddf719c8fb5344"
          }
        },
        "4e3a9069c6ca4af0aa1be6bef90e7016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "631119b3ca804418b2624d97b8ca1b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "561e9623d3c24907a9c6f7e971d144f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02c9cb6137844ba0b99b00353e4ffa00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55ad78ac9a5b4ff3aae7521266903bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c301ce9e4b644d2090ddf719c8fb5344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabi320/Data-Science-Projects/blob/master/English/English_Written_characters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYSnojsd2Hps"
      },
      "source": [
        "#  English Written characters\n",
        "![](https://www.researchgate.net/profile/Niranjan-S-K/publication/265317661/figure/fig1/AS:306759173459968@1450148494911/Sample-image-of-English-characters.png)\n",
        "\n",
        "This notebook will be used to classify 3,410 images of handwritten characters in English. This is a classification dataset that can be used for Computer Vision tasks. It contains 62 classes with 55 images of each class. The 62 classes are 0-9, A-Z and a-z."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o54bYja0H9_"
      },
      "source": [
        "# extract all files\n",
        "import zipfile\n",
        "zp = True\n",
        "if zp:\n",
        "    with zipfile.ZipFile(\"English Handwritten Characters.zip\",\"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"English Handwritten Characters\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TbYyMU931CS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "8c705dfc-bce8-407a-f7f2-b618b3863b64"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"English Handwritten Characters/english.csv\")\n",
        "df.sample(2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1246</th>\n",
              "      <td>Img/img023-037.png</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>Img/img060-018.png</td>\n",
              "      <td>x</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   image label\n",
              "1246  Img/img023-037.png     M\n",
              "3262  Img/img060-018.png     x"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx_dN3oDgY3j"
      },
      "source": [
        "original = df.label.unique().tolist() #original labels\n",
        "replace = list(range(len(original))) #encode the labels\n",
        "\n",
        "labels = dict(zip(original,replace)) #make a dictionary of labels\n",
        "\n",
        "\n",
        "save = True\n",
        "if save:\n",
        "  df.replace(to_replace = original, value = replace, inplace = True)\n",
        "  df.to_csv(\"English Handwritten Characters/english.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuo86SukkAp4",
        "outputId": "f71218fd-6e52-4a2c-86e4-417b77372f20"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3410 entries, 0 to 3409\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   image   3410 non-null   object\n",
            " 1   label   3410 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 53.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "xtoMbtv45Meu",
        "outputId": "8a98f90c-fc46-4dca-f450-436f0bab31bb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as imread\n",
        "random_image = df.sample()[\"image\"].values[0]# get the image name\n",
        "img=plt.imread(f\"English Handwritten Characters/{random_image}\")\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEYDzpWF683K",
        "outputId": "52da50f1-a77c-47f4-a014-40cccdf62bd2"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(900, 1200, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HqOVWGn9W6F"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3L2k33J9gVN"
      },
      "source": [
        "class EnglishWrittencharacters(Dataset):\n",
        "    \"\"\"English Written characters.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.English_Written_characters = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.English_Written_characters)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_name = os.path.join(self.root_dir,self.English_Written_characters[\"image\"][idx])\n",
        "                                \n",
        "        image = io.imread(img_name)\n",
        "        y_label = self.English_Written_characters[\"label\"][idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, y_label"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "56BIG9wk-IXg",
        "outputId": "691e91e4-0d9a-4750-c8a0-2058fb0874b2"
      },
      "source": [
        "English_dataset = EnglishWrittencharacters(csv_file='English Handwritten Characters/english.csv',root_dir='English Handwritten Characters',transform = transforms.ToTensor())\n",
        "                                    \n",
        "\n",
        "f\"the data has {English_dataset.__len__()} images\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the data has 3410 images'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaDbAJWe-0FG",
        "outputId": "47700af1-9b32-492e-9c6c-ebb4b5980831"
      },
      "source": [
        "train_size = int(English_dataset.__len__()*0.7)\n",
        "test_size = int(English_dataset.__len__() - train_size)\n",
        "train, test = torch.utils.data.random_split(English_dataset, [train_size,test_size])\n",
        "\n",
        "print(f\"train size: {train.__len__()}\\ntest size: {test.__len__()}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size: 2387\n",
            "test size: 1023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDTrO_rdZakP"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(train, batch_size=7, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test, batch_size=7, shuffle=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7izg7t_CaoMk"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 12, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(12, 16, 5)\n",
        "        self.fc1 = nn.Linear(222*297*16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 62) #62 classes (0-9.a-z,A-Z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net().to(device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6KdYjbXbTST"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v0VKtCwuVSg",
        "outputId": "c987dd14-9f5b-4736-b738-0c1c367f2af7"
      },
      "source": [
        "len(labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "CSwcT-OCvEnt",
        "outputId": "231f79dd-00a7-4dfb-a2da-28c77ca4bc92"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):    \n",
        "    plt.figure(figsize=(18, 16), dpi=80)\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, targets = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "\n",
        "# function to return key for any value\n",
        "def get_key(val):\n",
        "    for key, value in labels.items():\n",
        "         if val == value:\n",
        "             return key\n",
        " \n",
        "    return \"key doesn't exist\"\n",
        "print([get_key(target) for target in targets.numpy().tolist()])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1280 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['X', 'w', 'a', 'T', 'z', 'd', 'c']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5REr8SeEwW05",
        "outputId": "6eabefce-6798-4c24-dc1b-414a1f45da65"
      },
      "source": [
        "#random data for testing the net\n",
        "x = torch.rand((10,3,900,1200),device = device)\n",
        "print(net(x).size())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 62])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dko-BAQiFJCa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8886435d-b952-44ef-a2d1-9f463f5b5f7c"
      },
      "source": [
        "%%time\n",
        "for epoch in range(8):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        #inputs = inputs.permute(0,3,2,1)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 49:    # print every 50 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 50))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    50] loss: 4.138\n",
            "[1,   100] loss: 4.125\n",
            "[1,   150] loss: 4.128\n",
            "[1,   200] loss: 4.124\n",
            "[1,   250] loss: 4.126\n",
            "[1,   300] loss: 4.120\n",
            "[2,    50] loss: 4.106\n",
            "[2,   100] loss: 4.092\n",
            "[2,   150] loss: 4.073\n",
            "[2,   200] loss: 4.017\n",
            "[2,   250] loss: 3.976\n",
            "[2,   300] loss: 3.793\n",
            "[3,    50] loss: 3.408\n",
            "[3,   100] loss: 3.394\n",
            "[3,   150] loss: 3.177\n",
            "[3,   200] loss: 3.284\n",
            "[3,   250] loss: 3.135\n",
            "[3,   300] loss: 3.026\n",
            "[4,    50] loss: 2.557\n",
            "[4,   100] loss: 2.482\n",
            "[4,   150] loss: 2.451\n",
            "[4,   200] loss: 2.673\n",
            "[4,   250] loss: 2.491\n",
            "[4,   300] loss: 2.334\n",
            "[5,    50] loss: 1.815\n",
            "[5,   100] loss: 2.066\n",
            "[5,   150] loss: 1.890\n",
            "[5,   200] loss: 1.955\n",
            "[5,   250] loss: 1.901\n",
            "[5,   300] loss: 1.844\n",
            "[6,    50] loss: 1.051\n",
            "[6,   100] loss: 0.987\n",
            "[6,   150] loss: 1.151\n",
            "[6,   200] loss: 1.083\n",
            "[6,   250] loss: 1.076\n",
            "[6,   300] loss: 1.265\n",
            "[7,    50] loss: 0.462\n",
            "[7,   100] loss: 0.341\n",
            "[7,   150] loss: 0.398\n",
            "[7,   200] loss: 0.478\n",
            "[7,   250] loss: 0.455\n",
            "[7,   300] loss: 0.488\n",
            "[8,    50] loss: 0.191\n",
            "[8,   100] loss: 0.138\n",
            "[8,   150] loss: 0.175\n",
            "[8,   200] loss: 0.202\n",
            "[8,   250] loss: 0.249\n",
            "[8,   300] loss: 0.288\n",
            "Finished Training\n",
            "CPU times: user 33min 17s, sys: 4min 50s, total: 38min 8s\n",
            "Wall time: 37min 59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg4VamhMaais",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf19e49-7f3f-4c7b-84a6-eb1e718453ca"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        # calculate outputs by running images through the network \n",
        "        outputs = net(inputs)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 2387 train images: %.3f %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 2387 train images: 96.188 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv-sfVb9mCIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf33e926-3066-4d71-8b7a-2b57ac46a515"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        # calculate outputs by running images through the network \n",
        "        outputs = net(inputs)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 1023 test images: %.3f %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 1023 test images: 28.543 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiB0d2vZcYPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ed81c9-62a0-4522-b59f-a7a734b41610"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "classes = list(labels.values())\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, targets = data \n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)           \n",
        "        outputs = net(inputs)    \n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for target, prediction in zip(targets, predictions):\n",
        "            if target == prediction:\n",
        "                correct_pred[classes[target]] += 1\n",
        "            total_pred[classes[target]] += 1\n",
        "\n",
        "  \n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(get_key(classname), accuracy)) "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class 0     is: 46.7 %\n",
            "Accuracy for class 1     is: 5.9 %\n",
            "Accuracy for class 2     is: 42.9 %\n",
            "Accuracy for class 3     is: 12.5 %\n",
            "Accuracy for class 4     is: 6.7 %\n",
            "Accuracy for class 5     is: 18.8 %\n",
            "Accuracy for class 6     is: 38.5 %\n",
            "Accuracy for class 7     is: 27.3 %\n",
            "Accuracy for class 8     is: 46.7 %\n",
            "Accuracy for class 9     is: 7.7 %\n",
            "Accuracy for class A     is: 38.9 %\n",
            "Accuracy for class B     is: 0.0 %\n",
            "Accuracy for class C     is: 35.0 %\n",
            "Accuracy for class D     is: 31.2 %\n",
            "Accuracy for class E     is: 42.1 %\n",
            "Accuracy for class F     is: 11.8 %\n",
            "Accuracy for class G     is: 39.1 %\n",
            "Accuracy for class H     is: 12.5 %\n",
            "Accuracy for class I     is: 46.7 %\n",
            "Accuracy for class J     is: 41.7 %\n",
            "Accuracy for class K     is: 50.0 %\n",
            "Accuracy for class L     is: 50.0 %\n",
            "Accuracy for class M     is: 38.9 %\n",
            "Accuracy for class N     is: 29.4 %\n",
            "Accuracy for class O     is: 31.2 %\n",
            "Accuracy for class P     is: 40.0 %\n",
            "Accuracy for class Q     is: 39.1 %\n",
            "Accuracy for class R     is: 36.4 %\n",
            "Accuracy for class S     is: 50.0 %\n",
            "Accuracy for class T     is: 83.3 %\n",
            "Accuracy for class U     is: 30.4 %\n",
            "Accuracy for class V     is: 12.5 %\n",
            "Accuracy for class W     is: 60.0 %\n",
            "Accuracy for class X     is: 50.0 %\n",
            "Accuracy for class Y     is: 46.7 %\n",
            "Accuracy for class Z     is: 35.7 %\n",
            "Accuracy for class a     is: 40.0 %\n",
            "Accuracy for class b     is: 37.5 %\n",
            "Accuracy for class c     is: 15.0 %\n",
            "Accuracy for class d     is: 33.3 %\n",
            "Accuracy for class e     is: 11.8 %\n",
            "Accuracy for class f     is: 35.3 %\n",
            "Accuracy for class g     is: 14.3 %\n",
            "Accuracy for class h     is: 16.7 %\n",
            "Accuracy for class i     is: 7.1 %\n",
            "Accuracy for class j     is: 31.2 %\n",
            "Accuracy for class k     is: 5.0 %\n",
            "Accuracy for class l     is: 23.5 %\n",
            "Accuracy for class m     is: 54.5 %\n",
            "Accuracy for class n     is: 12.5 %\n",
            "Accuracy for class o     is: 0.0 %\n",
            "Accuracy for class p     is: 20.0 %\n",
            "Accuracy for class q     is: 55.6 %\n",
            "Accuracy for class r     is: 15.4 %\n",
            "Accuracy for class s     is: 7.7 %\n",
            "Accuracy for class t     is: 25.0 %\n",
            "Accuracy for class u     is: 22.2 %\n",
            "Accuracy for class v     is: 6.2 %\n",
            "Accuracy for class w     is: 14.3 %\n",
            "Accuracy for class x     is: 8.3 %\n",
            "Accuracy for class y     is: 18.2 %\n",
            "Accuracy for class z     is: 6.9 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "495Jw76420LL"
      },
      "source": [
        "## Resnet 18 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "989554b46ce345e988e2bf33949f7a15",
            "925d02b3a7d94f00a919edb0e363390a",
            "93d1644e1c844d34a3116e1a7a060638",
            "a8d0cf6c528045a6bf0ecc28d8934989",
            "a8861ab6b3be4c8db3d98cf26f0108a9",
            "4e3a9069c6ca4af0aa1be6bef90e7016",
            "631119b3ca804418b2624d97b8ca1b9d",
            "561e9623d3c24907a9c6f7e971d144f1",
            "02c9cb6137844ba0b99b00353e4ffa00",
            "55ad78ac9a5b4ff3aae7521266903bde",
            "c301ce9e4b644d2090ddf719c8fb5344"
          ]
        },
        "id": "lwx_UeKs22zd",
        "outputId": "d624c6be-f556-4ebe-a998-5350d5ed8bde"
      },
      "source": [
        "from torchvision import models\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 62.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 62)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "model_ft"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "989554b46ce345e988e2bf33949f7a15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=62, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQXhVjr928Gy"
      },
      "source": [
        "English_dataset = EnglishWrittencharacters(csv_file='English Handwritten Characters/english.csv',root_dir='English Handwritten Characters',transform = transforms.Compose([\n",
        "\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]))\n",
        "                                           \n",
        "                                           \n",
        "train_size = int(English_dataset.__len__()*0.7)\n",
        "test_size = int(English_dataset.__len__() - train_size)\n",
        "train, test = torch.utils.data.random_split(English_dataset, [train_size,test_size])\n",
        "\n",
        "                                           \n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=7, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test, batch_size=7, shuffle=False)\n",
        "                                           \n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN0NpRdj3AFj",
        "outputId": "7b3b12a3-4e8f-4747-c471-90310c84125a"
      },
      "source": [
        "%%time\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        #inputs = inputs.permute(0,3,2,1)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model_ft(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 49:    # print every 50 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 50))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    50] loss: 4.210\n",
            "[1,   100] loss: 3.931\n",
            "[1,   150] loss: 3.556\n",
            "[1,   200] loss: 3.324\n",
            "[1,   250] loss: 3.111\n",
            "[1,   300] loss: 2.825\n",
            "[2,    50] loss: 2.588\n",
            "[2,   100] loss: 2.447\n",
            "[2,   150] loss: 2.260\n",
            "[2,   200] loss: 2.311\n",
            "[2,   250] loss: 2.170\n",
            "[2,   300] loss: 2.015\n",
            "[3,    50] loss: 1.865\n",
            "[3,   100] loss: 1.872\n",
            "[3,   150] loss: 1.867\n",
            "[3,   200] loss: 1.795\n",
            "[3,   250] loss: 1.899\n",
            "[3,   300] loss: 1.826\n",
            "[4,    50] loss: 1.666\n",
            "[4,   100] loss: 1.601\n",
            "[4,   150] loss: 1.609\n",
            "[4,   200] loss: 1.595\n",
            "[4,   250] loss: 1.487\n",
            "[4,   300] loss: 1.577\n",
            "[5,    50] loss: 1.611\n",
            "[5,   100] loss: 1.362\n",
            "[5,   150] loss: 1.604\n",
            "[5,   200] loss: 1.544\n",
            "[5,   250] loss: 1.362\n",
            "[5,   300] loss: 1.336\n",
            "[6,    50] loss: 1.379\n",
            "[6,   100] loss: 1.349\n",
            "[6,   150] loss: 1.407\n",
            "[6,   200] loss: 1.349\n",
            "[6,   250] loss: 1.557\n",
            "[6,   300] loss: 1.164\n",
            "[7,    50] loss: 1.379\n",
            "[7,   100] loss: 1.366\n",
            "[7,   150] loss: 1.360\n",
            "[7,   200] loss: 1.314\n",
            "[7,   250] loss: 1.228\n",
            "[7,   300] loss: 1.309\n",
            "[8,    50] loss: 1.205\n",
            "[8,   100] loss: 1.314\n",
            "[8,   150] loss: 1.212\n",
            "[8,   200] loss: 1.252\n",
            "[8,   250] loss: 1.222\n",
            "[8,   300] loss: 1.308\n",
            "[9,    50] loss: 1.171\n",
            "[9,   100] loss: 1.241\n",
            "[9,   150] loss: 1.194\n",
            "[9,   200] loss: 1.131\n",
            "[9,   250] loss: 1.274\n",
            "[9,   300] loss: 1.275\n",
            "[10,    50] loss: 1.190\n",
            "[10,   100] loss: 0.931\n",
            "[10,   150] loss: 1.169\n",
            "[10,   200] loss: 1.309\n",
            "[10,   250] loss: 1.286\n",
            "[10,   300] loss: 1.245\n",
            "Finished Training\n",
            "CPU times: user 15min 9s, sys: 23.2 s, total: 15min 32s\n",
            "Wall time: 15min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8GiBGWQ3CTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1054d6b5-f9aa-4c8b-e7ff-31d2eb4cb73d"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        # calculate outputs by running images through the network \n",
        "        outputs = model_ft(inputs)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 2387 train images: %.3f %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 2387 train images: 68.287 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekoRYrjUz13w",
        "outputId": "511a0508-8b50-4fcb-96d7-8709f0ff8e0f"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        # calculate outputs by running images through the network \n",
        "        outputs = model_ft(inputs)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 1023 test images: %.3f %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 1023 test images: 64.027 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZONxqwIp3JtC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f20cbc-5012-422c-f8d4-82dbdf7db77e"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "classes = list(labels.values())\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, targets = data \n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)           \n",
        "        outputs = model_ft(inputs)    \n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for target, prediction in zip(targets, predictions):\n",
        "            if target == prediction:\n",
        "                correct_pred[classes[target]] += 1\n",
        "            total_pred[classes[target]] += 1\n",
        "\n",
        "  \n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(get_key(classname), accuracy))       "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class 0     is: 5.0 %\n",
            "Accuracy for class 1     is: 82.6 %\n",
            "Accuracy for class 2     is: 54.5 %\n",
            "Accuracy for class 3     is: 80.0 %\n",
            "Accuracy for class 4     is: 86.7 %\n",
            "Accuracy for class 5     is: 61.5 %\n",
            "Accuracy for class 6     is: 73.7 %\n",
            "Accuracy for class 7     is: 86.7 %\n",
            "Accuracy for class 8     is: 88.9 %\n",
            "Accuracy for class 9     is: 61.1 %\n",
            "Accuracy for class A     is: 88.9 %\n",
            "Accuracy for class B     is: 81.2 %\n",
            "Accuracy for class C     is: 50.0 %\n",
            "Accuracy for class D     is: 81.2 %\n",
            "Accuracy for class E     is: 72.7 %\n",
            "Accuracy for class F     is: 71.4 %\n",
            "Accuracy for class G     is: 60.0 %\n",
            "Accuracy for class H     is: 76.9 %\n",
            "Accuracy for class I     is: 41.2 %\n",
            "Accuracy for class J     is: 69.2 %\n",
            "Accuracy for class K     is: 65.0 %\n",
            "Accuracy for class L     is: 64.7 %\n",
            "Accuracy for class M     is: 66.7 %\n",
            "Accuracy for class N     is: 64.7 %\n",
            "Accuracy for class O     is: 95.0 %\n",
            "Accuracy for class P     is: 71.4 %\n",
            "Accuracy for class Q     is: 64.7 %\n",
            "Accuracy for class R     is: 47.6 %\n",
            "Accuracy for class S     is: 87.0 %\n",
            "Accuracy for class T     is: 78.6 %\n",
            "Accuracy for class U     is: 81.2 %\n",
            "Accuracy for class V     is: 50.0 %\n",
            "Accuracy for class W     is: 68.8 %\n",
            "Accuracy for class X     is: 100.0 %\n",
            "Accuracy for class Y     is: 60.0 %\n",
            "Accuracy for class Z     is: 44.4 %\n",
            "Accuracy for class a     is: 80.0 %\n",
            "Accuracy for class b     is: 83.3 %\n",
            "Accuracy for class c     is: 60.0 %\n",
            "Accuracy for class d     is: 53.3 %\n",
            "Accuracy for class e     is: 75.0 %\n",
            "Accuracy for class f     is: 72.2 %\n",
            "Accuracy for class g     is: 62.5 %\n",
            "Accuracy for class h     is: 80.0 %\n",
            "Accuracy for class i     is: 45.0 %\n",
            "Accuracy for class j     is: 60.0 %\n",
            "Accuracy for class k     is: 25.0 %\n",
            "Accuracy for class l     is: 55.0 %\n",
            "Accuracy for class m     is: 93.8 %\n",
            "Accuracy for class n     is: 47.1 %\n",
            "Accuracy for class o     is: 25.0 %\n",
            "Accuracy for class p     is: 28.0 %\n",
            "Accuracy for class q     is: 47.1 %\n",
            "Accuracy for class r     is: 58.8 %\n",
            "Accuracy for class s     is: 38.5 %\n",
            "Accuracy for class t     is: 80.0 %\n",
            "Accuracy for class u     is: 72.7 %\n",
            "Accuracy for class v     is: 63.6 %\n",
            "Accuracy for class w     is: 61.5 %\n",
            "Accuracy for class x     is: 37.5 %\n",
            "Accuracy for class y     is: 68.2 %\n",
            "Accuracy for class z     is: 100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTja8kAbBeUb"
      },
      "source": [
        "## MobileNetV2 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAs_-1Nr0A1d",
        "outputId": "5b54030a-dd6a-4549-b39b-f92945581c7e"
      },
      "source": [
        "from torchvision import models\n",
        "model_vgg = models.mobilenet_v2(pretrained=True)\n",
        "model_vgg\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): ConvBNActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): ConvBNActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8hpLEwl1lYZ",
        "outputId": "2ce111f3-7ddd-481b-e2b0-3ce1f949f874"
      },
      "source": [
        "num_ftrs = model_vgg.classifier[1].in_features\n",
        "# Here the size of each output sample is set to 62.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_vgg.classifier[1] = nn.Linear(num_ftrs, 62)\n",
        "\n",
        "model_vgg = model_vgg.to(device)\n",
        "model_vgg"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileNetV2(\n",
              "  (features): Sequential(\n",
              "    (0): ConvBNActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "    (1): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (2): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (3): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (4): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (5): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (6): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (7): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (8): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (9): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (10): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (11): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (12): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (13): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (14): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (15): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (16): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (17): InvertedResidual(\n",
              "      (conv): Sequential(\n",
              "        (0): ConvBNActivation(\n",
              "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (1): ConvBNActivation(\n",
              "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU6(inplace=True)\n",
              "        )\n",
              "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (18): ConvBNActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU6(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=1280, out_features=62, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCgbdMrU08cu"
      },
      "source": [
        "English_dataset = EnglishWrittencharacters(csv_file='English Handwritten Characters/english.csv',root_dir='English Handwritten Characters',transform = transforms.Compose([\n",
        "\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]))\n",
        "                                           \n",
        "                                           \n",
        "train_size = int(English_dataset.__len__()*0.7)\n",
        "test_size = int(English_dataset.__len__() - train_size)\n",
        "train, test = torch.utils.data.random_split(English_dataset, [train_size,test_size])\n",
        "\n",
        "                                           \n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=7, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test, batch_size=7, shuffle=False)\n",
        "                                           \n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model_vgg.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEwZVx8q0_cg",
        "outputId": "a30d6f15-856a-46de-be07-b736bdf7b50e"
      },
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        #inputs = inputs.permute(0,3,2,1)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model_vgg(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 49:    # print every 50 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 50))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,    50] loss: 4.176\n",
            "[1,   100] loss: 4.031\n",
            "[1,   150] loss: 3.754\n",
            "[1,   200] loss: 3.403\n",
            "[1,   250] loss: 3.130\n",
            "[1,   300] loss: 3.035\n",
            "[2,    50] loss: 2.596\n",
            "[2,   100] loss: 2.506\n",
            "[2,   150] loss: 2.344\n",
            "[2,   200] loss: 2.392\n",
            "[2,   250] loss: 2.166\n",
            "[2,   300] loss: 2.133\n",
            "[3,    50] loss: 1.954\n",
            "[3,   100] loss: 2.040\n",
            "[3,   150] loss: 1.912\n",
            "[3,   200] loss: 1.853\n",
            "[3,   250] loss: 1.839\n",
            "[3,   300] loss: 1.682\n",
            "[4,    50] loss: 1.662\n",
            "[4,   100] loss: 1.640\n",
            "[4,   150] loss: 1.579\n",
            "[4,   200] loss: 1.532\n",
            "[4,   250] loss: 1.456\n",
            "[4,   300] loss: 1.714\n",
            "[5,    50] loss: 1.462\n",
            "[5,   100] loss: 1.594\n",
            "[5,   150] loss: 1.647\n",
            "[5,   200] loss: 1.499\n",
            "[5,   250] loss: 1.483\n",
            "[5,   300] loss: 1.600\n",
            "[6,    50] loss: 1.355\n",
            "[6,   100] loss: 1.534\n",
            "[6,   150] loss: 1.566\n",
            "[6,   200] loss: 1.544\n",
            "[6,   250] loss: 1.534\n",
            "[6,   300] loss: 1.254\n",
            "[7,    50] loss: 1.317\n",
            "[7,   100] loss: 1.260\n",
            "[7,   150] loss: 1.445\n",
            "[7,   200] loss: 1.350\n",
            "[7,   250] loss: 1.446\n",
            "[7,   300] loss: 1.286\n",
            "[8,    50] loss: 1.243\n",
            "[8,   100] loss: 1.315\n",
            "[8,   150] loss: 1.314\n",
            "[8,   200] loss: 1.245\n",
            "[8,   250] loss: 1.306\n",
            "[8,   300] loss: 1.386\n",
            "[9,    50] loss: 1.354\n",
            "[9,   100] loss: 1.341\n",
            "[9,   150] loss: 1.242\n",
            "[9,   200] loss: 1.363\n",
            "[9,   250] loss: 1.336\n",
            "[9,   300] loss: 1.356\n",
            "[10,    50] loss: 1.379\n",
            "[10,   100] loss: 1.222\n",
            "[10,   150] loss: 1.213\n",
            "[10,   200] loss: 1.257\n",
            "[10,   250] loss: 1.167\n",
            "[10,   300] loss: 1.402\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xNqOOx5CUlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974f8b9a-6707-49c5-e790-964d6e167f5d"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in trainloader:\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        # calculate outputs by running images through the network \n",
        "        outputs = model_vgg(inputs)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 2387 train images: %.3f %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 2387 train images: 66.150 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-XsIT5qCZ6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839074d2-e1db-4318-b72d-2599858c39a7"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, targets = data\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        # calculate outputs by running images through the network \n",
        "        outputs = model_vgg(inputs)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 1023 test images: %.3f %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 1023 test images: 62.268 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwnO8BqfCkFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "160e8007-848b-4a30-d17b-4f604e748c7c"
      },
      "source": [
        "# prepare to count predictions for each class\n",
        "classes = list(labels.values())\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, targets = data \n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)           \n",
        "        outputs = model_vgg(inputs)    \n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for target, prediction in zip(targets, predictions):\n",
        "            if target == prediction:\n",
        "                correct_pred[classes[target]] += 1\n",
        "            total_pred[classes[target]] += 1\n",
        "\n",
        "  \n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(get_key(classname), accuracy))    "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class 0     is: 0.0 %\n",
            "Accuracy for class 1     is: 58.8 %\n",
            "Accuracy for class 2     is: 55.6 %\n",
            "Accuracy for class 3     is: 61.5 %\n",
            "Accuracy for class 4     is: 57.1 %\n",
            "Accuracy for class 5     is: 77.8 %\n",
            "Accuracy for class 6     is: 65.0 %\n",
            "Accuracy for class 7     is: 43.8 %\n",
            "Accuracy for class 8     is: 70.0 %\n",
            "Accuracy for class 9     is: 25.0 %\n",
            "Accuracy for class A     is: 82.4 %\n",
            "Accuracy for class B     is: 78.9 %\n",
            "Accuracy for class C     is: 55.6 %\n",
            "Accuracy for class D     is: 68.4 %\n",
            "Accuracy for class E     is: 80.0 %\n",
            "Accuracy for class F     is: 63.2 %\n",
            "Accuracy for class G     is: 90.9 %\n",
            "Accuracy for class H     is: 73.3 %\n",
            "Accuracy for class I     is: 41.2 %\n",
            "Accuracy for class J     is: 64.3 %\n",
            "Accuracy for class K     is: 65.0 %\n",
            "Accuracy for class L     is: 87.5 %\n",
            "Accuracy for class M     is: 86.7 %\n",
            "Accuracy for class N     is: 33.3 %\n",
            "Accuracy for class O     is: 66.7 %\n",
            "Accuracy for class P     is: 58.8 %\n",
            "Accuracy for class Q     is: 58.8 %\n",
            "Accuracy for class R     is: 50.0 %\n",
            "Accuracy for class S     is: 73.7 %\n",
            "Accuracy for class T     is: 90.0 %\n",
            "Accuracy for class U     is: 61.9 %\n",
            "Accuracy for class V     is: 94.7 %\n",
            "Accuracy for class W     is: 80.0 %\n",
            "Accuracy for class X     is: 61.1 %\n",
            "Accuracy for class Y     is: 70.6 %\n",
            "Accuracy for class Z     is: 28.6 %\n",
            "Accuracy for class a     is: 73.3 %\n",
            "Accuracy for class b     is: 88.9 %\n",
            "Accuracy for class c     is: 38.9 %\n",
            "Accuracy for class d     is: 57.1 %\n",
            "Accuracy for class e     is: 68.4 %\n",
            "Accuracy for class f     is: 65.0 %\n",
            "Accuracy for class g     is: 70.0 %\n",
            "Accuracy for class h     is: 83.3 %\n",
            "Accuracy for class i     is: 66.7 %\n",
            "Accuracy for class j     is: 38.9 %\n",
            "Accuracy for class k     is: 55.6 %\n",
            "Accuracy for class l     is: 58.3 %\n",
            "Accuracy for class m     is: 66.7 %\n",
            "Accuracy for class n     is: 66.7 %\n",
            "Accuracy for class o     is: 44.4 %\n",
            "Accuracy for class p     is: 22.2 %\n",
            "Accuracy for class q     is: 81.8 %\n",
            "Accuracy for class r     is: 47.4 %\n",
            "Accuracy for class s     is: 43.8 %\n",
            "Accuracy for class t     is: 64.3 %\n",
            "Accuracy for class u     is: 68.8 %\n",
            "Accuracy for class v     is: 69.2 %\n",
            "Accuracy for class w     is: 35.7 %\n",
            "Accuracy for class x     is: 61.1 %\n",
            "Accuracy for class y     is: 50.0 %\n",
            "Accuracy for class z     is: 71.4 %\n"
          ]
        }
      ]
    }
  ]
}