{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235bfe77-2a52-4c2e-ae4b-012fbc53d25c",
   "metadata": {},
   "source": [
    "# Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2b42ee-98d5-4479-bc67-ded496b26a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from random import randint as ri\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from collections import Counter\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90f2a7b-028c-4607-8367-f632147f94de",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/age_gender.csv.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4496/3869439147.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/age_gender.csv.zip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pixels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pixels'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"float32\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#converting data to numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ethnicity\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"index\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[1;31m# ZIP Compression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"zip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_BytesZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, archive_name, **kwargs)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;31m# TextIOBase, TextIOWrapper, mmap]]]\"; expected \"Union[Union[str,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[1;31m# _PathLike[str]], IO[bytes]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs_zip\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1237\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/age_gender.csv.zip'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data/age_gender.csv.zip')\n",
    "df['pixels']=df['pixels'].apply(lambda x:  np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\n",
    "df = df[df[\"ethnicity\"]!=4].reset_index()\n",
    "df.drop(\"index\",axis = 1, inplace = True)\n",
    "bins = [0,18,35,50,70,120]\n",
    "labels = [0,1,2,3,4]\n",
    "df['AgeGroup'] = pd.cut(df['age'], bins=bins, labels=labels, right=False).astype(int)\n",
    "\n",
    "samples = df.sample(100)\n",
    "df = df.drop(samples.index)\n",
    "df = df.reset_index()\n",
    "df = df.drop(\"index\",axis = 1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068f339b-6ca9-4204-932c-3c6f3d8e87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['gender'], df['ethnicity'])\n",
    "#df[\"geneth\"] = str(df['gender']) + str(df['ethnicity'])\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c2649-9cff-40b6-acdd-52d65a7d404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AgeGroup'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ec53f5-a3c3-407d-94d0-7a4939218008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rand_image():\n",
    "    \"\"\"\n",
    "    this function plots a random image.\n",
    "    the title of the image is the index of the image and the features.\n",
    "    \"\"\"\n",
    "    num = ri(0,df.shape[0])\n",
    "    labels = dict(zip(df.columns.tolist()[:-1],df.loc[num].tolist()[:-1]))\n",
    "    plt.title(f\"sample #{num}- {list(labels.keys())[0]}: {list(labels.values())[0]}, {list(labels.keys())[1]}: {list(labels.values())[1]}, {list(labels.keys())[2]}: {list(labels.values())[2]}\")\n",
    "    plt.imshow(df[\"pixels\"][num].reshape(48,48),cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd1b8d-0a80-450f-a8c7-03130dc7295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rand_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd8091-d219-43b0-b390-64255f9e6176",
   "metadata": {},
   "source": [
    "## Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bedc97-6bf1-42ae-9a9e-7f910045abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferImages(Dataset):\n",
    "    \"\"\"images in a format for transfer learning\"\"\"\n",
    "\n",
    "    def __init__(self, my_df, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.TransferImages = my_df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.TransferImages)\n",
    "\n",
    "    def __getitem__(self, idx):                       \n",
    "        image = self.TransferImages.loc[idx,\"pixels\"]\n",
    "        #image = np.array(image.split(), dtype=\"float32\")\n",
    "        #image = image.reshape(48, 48)\n",
    "        image = np.repeat(image.reshape(48, 48)[...,np.newaxis], 3, -1)\n",
    "        y_label = self.TransferImages[\"ethnicity\"][idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y_label\n",
    "#create transforms\n",
    "my_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.RandomSizedCrop(24),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=48),  \n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])])\n",
    "\n",
    "data = TransferImages(df, transform = my_transforms)\n",
    "\n",
    "train_size = int(data.__len__()*0.70)\n",
    "valid_size = int(data.__len__()*0.15)\n",
    "test_size = int(data.__len__() - valid_size - train_size)\n",
    "\n",
    "train, valid, test = torch.utils.data.random_split(data, [train_size,valid_size,test_size])\n",
    "\n",
    "print(f\"train size: {train.__len__()}\\nvalid size: {valid.__len__()}\\ntest size: {test.__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604e29b-b1b3-4ec1-a76b-d68e487cf873",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "my_data = {'train':train,'valid':valid,'test':test}\n",
    "dataloaders = {\n",
    "    'train': DataLoader(my_data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(my_data['valid'], batch_size=batch_size, shuffle=True),\n",
    "    'test': DataLoader(my_data['test'], batch_size=batch_size, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e62f18f-d615-4a38-bbc1-ca616ab6d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.wide_resnet50_2(pretrained=True)\n",
    "#model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f509da6-00d7-41ca-a53e-d9d4fafb4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model weights\n",
    "#for param in model.parameters():\n",
    "    #param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2653c216-1ada-40e7-8ee9-a7bc4e0ce8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "                      nn.Linear(num_features, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, 4),                   \n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab06c3-c1af-435e-b407-28337f48cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to train on a gpu\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "print(f'Train on gpu: {train_on_gpu}')\n",
    "\n",
    "# Number of gpus\n",
    "if train_on_gpu:\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f'{gpu_count} gpus detected.')\n",
    "    if gpu_count > 1:\n",
    "        multi_gpu = True\n",
    "    else:\n",
    "        multi_gpu = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if train_on_gpu:\n",
    "    model = model.to(device)\n",
    "\n",
    "if multi_gpu:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3396dc81-3924-459d-82cb-3fa02b0e3934",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8812a-4cef-4f11-92c4-79d84ecdce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def train_loop(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=20,\n",
    "          print_every=1):\n",
    "    \"\"\"Train a PyTorch Model\n",
    "    Params\n",
    "    --------\n",
    "        model (PyTorch model): cnn to train\n",
    "        criterion (PyTorch loss): objective to minimize\n",
    "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
    "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
    "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
    "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
    "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
    "        n_epochs (int): maximum number of training epochs\n",
    "        print_every (int): frequency of epochs to print training stats\n",
    "    Returns\n",
    "    --------\n",
    "        model (PyTorch model): trained cnn with best weights\n",
    "        history (DataFrame): history of train and validation loss and accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Early stopping intialization\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "\n",
    "        # Set to training\n",
    "        model.train()\n",
    "        start = timer()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "            # Tensors to gpu\n",
    "            if train_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Predicted outputs are log probabilities\n",
    "            output = model(data)\n",
    "\n",
    "            # Loss and backpropagation of gradients\n",
    "            loss = criterion(output, target.long())\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track train loss by multiplying average loss by number of examples in batch\n",
    "            train_loss += loss.item() * data.size(0)\n",
    "\n",
    "            # Calculate accuracy by finding max log probability\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            # Need to convert correct tensor from int to float to average\n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            # Multiply average accuracy times the number of examples in batch\n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "            # Track training progress\n",
    "            print(\n",
    "                f'Epoch: {epoch+1}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "                end='\\r')\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "                # Set to evaluation mode\n",
    "                model.eval()\n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "                    # Tensors to gpu\n",
    "                    if train_on_gpu:\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                    # Forward pass\n",
    "                    output = model(data)\n",
    "\n",
    "                    # Validation loss\n",
    "                    loss = criterion(output, target.long())\n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "\n",
    "                    # Calculate validation accuracy\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch+1} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch + 1\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch+1}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "\n",
    "                        # Load the best state dict\n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Record overall time and print out stats\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "    )\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b3b12-d43d-4512-8430-19e87ea03c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the model\n",
    "model, history = train_loop(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'],\n",
    "    dataloaders['val'],\n",
    "    save_file_name=\"Data/model1.pt\",\n",
    "    max_epochs_stop=10,\n",
    "    n_epochs=100,\n",
    "    print_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120481ec-21f0-4b96-9acc-33b78b295da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy_report(loader = None, model = None, n_classes = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    >loader - the data for accuracy testing.\n",
    "    >model - the neural network.\n",
    "    <n_classes - the number of classes.\n",
    "    \n",
    "    Output: \n",
    "    >>>[my_classes,acc]\n",
    "    > my_classes - accuracy per classes. non existant taregts in the test set are set to nan value.\n",
    "    > acc - overall accuracy.\n",
    "    \"\"\"\n",
    "    my_classes = []\n",
    "\n",
    "    classes = [n_class for n_class in range(n_classes)]\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, targets = data \n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)           \n",
    "            outputs = model(inputs)    \n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            # collect the correct predictions for each class\n",
    "            for target, prediction in zip(targets, predictions):\n",
    "                if target == prediction:\n",
    "                    correct_pred[classes[target]] += 1\n",
    "                total_pred[classes[target]] += 1\n",
    "\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        try:\n",
    "            accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "\n",
    "            my_classes.append(accuracy)\n",
    "        except ZeroDivisionError:\n",
    "            my_classes.append(np.nan)\n",
    "            continue\n",
    "    \n",
    "    acc =  100 * float(sum(correct_pred.values())/sum(total_pred.values()))\n",
    "    \n",
    "    return [dict(zip(classes,my_classes)), acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f5e53e-051b-4908-9df4-33532a75839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_test_acc = Accuracy_report(loader = dataloaders[\"test\"],model = model, n_classes = 4)\n",
    "b1_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6f9c1-b463-4a8e-a97f-b32bbb8c120c",
   "metadata": {},
   "source": [
    "# gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9db772-683d-476b-a379-2f260b8910ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferImages2(Dataset):\n",
    "    \"\"\"images in a format for transfer learning\"\"\"\n",
    "\n",
    "    def __init__(self, my_df, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.TransferImages2 = my_df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.TransferImages2)\n",
    "\n",
    "    def __getitem__(self, idx):                       \n",
    "        image = self.TransferImages2.loc[idx,\"pixels\"]\n",
    "        #image = np.array(image.split(), dtype=\"float32\")\n",
    "        image = np.repeat(image.reshape(48, 48)[...,np.newaxis], 3, -1)\n",
    "        \n",
    "        y_label = self.TransferImages2[\"gender\"][idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y_label\n",
    "    \n",
    "my_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.RandomSizedCrop(40),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=48),  \n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "data2 = TransferImages2(df, transform = my_transforms)\n",
    "\n",
    "train2, valid2, test2 = torch.utils.data.random_split(data2, [train_size,valid_size,test_size])\n",
    "\n",
    "\n",
    "my_data = {'train2':train2,'valid2':valid2,'test2':test2}\n",
    "dataloaders = {\n",
    "    'train2': DataLoader(my_data['train2'], batch_size=batch_size, shuffle=True),\n",
    "    'val2': DataLoader(my_data['valid2'], batch_size=batch_size, shuffle=True),\n",
    "    'test2': DataLoader(my_data['test2'], batch_size=batch_size, shuffle=True)\n",
    "}\n",
    "\n",
    "\n",
    "model2 = models.wide_resnet50_2(pretrained=True)\n",
    "num_features = model2.fc.in_features\n",
    "model2.fc = nn.Sequential(\n",
    "                      nn.Linear(num_features, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, 2),                   \n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "model2.to(device)\n",
    "\n",
    "criterion2 = nn.NLLLoss()\n",
    "optimizer2 = optim.Adam(model2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79835253-9503-4e9f-9eae-ad4f1edb3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the model\n",
    "model2, history2 = train_loop(\n",
    "    model2,\n",
    "    criterion2,\n",
    "    optimizer2,\n",
    "    dataloaders['train2'],\n",
    "    dataloaders['val2'],\n",
    "    save_file_name=\"Data/model2.pt\",\n",
    "    max_epochs_stop=10,\n",
    "    n_epochs=100,\n",
    "    print_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd1816c-5936-4d18-a32d-1fa5294716b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_test_acc = Accuracy_report(loader = dataloaders[\"test2\"],model = model2, n_classes = 2)\n",
    "b2_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90207a42-66ed-4a9a-817e-373fd94d1f08",
   "metadata": {},
   "source": [
    "# Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f11b0c-65a3-4a4d-9cd2-c1deed9ca8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferImages3(Dataset):\n",
    "    \"\"\"images in a format for transfer learning\"\"\"\n",
    "\n",
    "    def __init__(self, my_df, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.TransferImages3 = my_df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.TransferImages3)\n",
    "\n",
    "    def __getitem__(self, idx):                       \n",
    "        image = self.TransferImages3.loc[idx,\"pixels\"]\n",
    "        #image = np.array(image.split(), dtype=\"float32\")\n",
    "        image = np.repeat(image.reshape(48, 48)[...,np.newaxis], 3, -1)\n",
    "        \n",
    "        y_label = self.TransferImages3[\"AgeGroup\"][idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y_label\n",
    "    \n",
    "#create transforms\n",
    "my_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.RandomSizedCrop(24),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=48),  \n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])])\n",
    "\n",
    "data3 = TransferImages3(df, transform = my_transforms)\n",
    "\n",
    "train3, valid3, test3 = torch.utils.data.random_split(data3, [train_size,valid_size,test_size])\n",
    "\n",
    "\n",
    "my_data = {'train3':train3,'valid3':valid3,'test3':test3}\n",
    "dataloaders = {\n",
    "    'train3': DataLoader(my_data['train3'], batch_size=batch_size, shuffle=True),\n",
    "    'val3': DataLoader(my_data['valid3'], batch_size=batch_size, shuffle=True),\n",
    "    'test3': DataLoader(my_data['test3'], batch_size=batch_size, shuffle=True)\n",
    "}\n",
    "\n",
    "\n",
    "model3 = models.wide_resnet50_2(pretrained=True)\n",
    "num_features = model3.fc.in_features\n",
    "model3.fc = nn.Sequential(\n",
    "                      nn.Linear(num_features, 256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, 5),                   \n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "model3.to(device)\n",
    "\n",
    "criterion3 = nn.NLLLoss()#weight = torch.tensor((1/df.AgeGroup.value_counts(normalize = True)).tolist(), device = device))\n",
    "optimizer3 = optim.Adam(model3.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72129a4-e99f-406d-bee2-47ae69cbfab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the model\n",
    "model3, history3 = train_loop(\n",
    "    model3,\n",
    "    criterion3,\n",
    "    optimizer3,\n",
    "    dataloaders['train3'],\n",
    "    dataloaders['val3'],\n",
    "    save_file_name=\"Data/model3.pt\",\n",
    "    max_epochs_stop=10,\n",
    "    n_epochs=100,\n",
    "    print_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38908025-d7ae-4973-8ad2-6cd09423fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_test_acc = Accuracy_report(loader = dataloaders[\"test3\"],model = model3, n_classes = 5)\n",
    "b3_test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721fba20-7235-4431-a8a8-b1023ce1f07a",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec2a77d-0247-4dbe-8f8c-e0176d88cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"ethnicity\",\"gender\",\"AgeGroup\",\"pixels\"]]\n",
    "samples = samples[[\"ethnicity\",\"gender\",\"AgeGroup\",\"pixels\"]]\n",
    "samples.index = np.array([i for i in range(100)])\n",
    "samples.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c96de-a234-4da5-bdb9-b37a9fbde79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loader(model_path = None, label = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    >model_path - the path to current model.\n",
    "    >label -the label to predict. \n",
    "    \"\"\"\n",
    "    model = models.wide_resnet50_2()\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "                          nn.Linear(num_features, 256),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Dropout(0.4),\n",
    "                          nn.Linear(256, len(df[label].unique().tolist()),                   \n",
    "                          nn.LogSoftmax(dim=1)))\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model.eval()\n",
    "\n",
    "models = {f\"model{i}\" : model_loader(f\"Data/model{i+1}.pt\",df.columns[i]) for i in range(3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd532af-9211-4b3a-8812-b5fed24a5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ethnicities = dict(zip([i for i in range(len(df.ethnicity.unique().tolist()))], [\"white\",\"black\",\"asian\",\"indian\"]))\n",
    "genders = dict(zip([i for i in range(len(df.gender.unique().tolist()))], [\"male\",\"female\"]))\n",
    "AgeGroups = dict(zip([i for i in range(len(df.AgeGroup.unique().tolist()))], [\"child\",\"young adult\",\"adult\",\"middle aged\",\"elder\"]))\n",
    "    \n",
    "\n",
    "\n",
    "def plot_image(num):\n",
    "    \"\"\"\n",
    "    this function plots a random image.\n",
    "    the title of the image is the index of the image and the features.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = dict(zip(df.columns.tolist()[:-1],samples.loc[num].tolist()[:-1]))\n",
    "    plt.title(f\"sample #{num+1}- {list(labels.keys())[0]}: {ethnicities[list(labels.values())[0]]}, {list(labels.keys())[1]}: {genders[list(labels.values())[1]]}, {list(labels.keys())[2]}: {AgeGroups[list(labels.values())[2]]}\")\n",
    "    plt.imshow(samples[\"pixels\"][num].reshape(48,48),cmap = 'gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764068a-1fe9-4023-9568-84e605e00eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(model = None, my_transforms = None, num = None):\n",
    "    input_image = my_transforms(np.repeat(samples.pixels.iloc[num].reshape(48, 48)[...,np.newaxis], 3, -1)).unsqueeze(0)\n",
    "    output = model(input_image)\n",
    "    _, pred = torch.max(output, dim=1)\n",
    "    return int(pred)\n",
    "\n",
    "def profile(num):\n",
    "    plot_image(num)\n",
    "    ethnicity = ethnicities[predictor(models[\"model0\"],transforms.ToTensor(),num = num)]\n",
    "    gender = genders[predictor(models[\"model1\"],transforms.ToTensor(),num = num)]\n",
    "    AgeGroup = AgeGroups[predictor(models[\"model2\"],transforms.ToTensor(),num = num)]\n",
    "    print(f\"Profile Prediction number #{num+1}:\\n______________________________\\n|\\tethnicity: {ethnicity}\\n|\\tgender: {gender}\\n|\\tAgeGroup: {AgeGroup}\\n______________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc245c1-f99c-4305-8d8d-e630e42a8cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv(\"Data/my_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ec560-df65-40c0-8ee0-5cec42894e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = ri(0,samples.shape[0]-1)\n",
    "profile(num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
